# Basic info
replicaCount: 1

image:
  repository: streamreactor/ftp
  tag: 1.2.2
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

podManagementPolicy: OrderedReady

# kafka ssl
# The key and truststores file data are the base64 encoded contents of the files. YOU MUST PROVIDE THE DATA BASE64 encoded
# and added to the kafka secret and mounted into /mnt/connector-secrets
kafka:
  # replicationFactor for connect topics
  replicationFactor: 3
  securityProtocol:
  ssl:
    enabled: false
    trustStoreFileData:
    trustStorePassword:
    keyStoreFileData:
    keyStorePassword:
  sasl:
    enabled: false
    # keyTabData is the contents kerberos keytab file is using kerberos
    keyTabData: |-
             
    # jaasFileData is the contents of the kafka jaas file
    jaasFileData: |-
          
    #GSSAPI, SCRAM or PLAIN
    mechanism: GSSAPI
    # kerberos krb5 contents
    krb5Conf: |-

  bootstrapServers: 
    - name: kafka
      port: 9092
      sslPort: 9093
      saslSslPort: 9094
      saslPlainTextPort: 9095       

schemaRegistries:
  enabled: true
  hosts:
    - host: schema-registry
      protocol: http
      port: 8081
      jmxPort: 9102    
           
# secretsProvider is either env (k8), vault (hashicorp) or azure (keyvault)
secretsProvider: env

#javaHeap option
javaHeap: "256M"

# clusterName The connect cluster name. This is the consumer group id for the backing topics
clusterName: "__REQUIRED__"

# restPort The rest port of Connect
restPort: 8083

# logLevel The log4j level
logLevel: INFO

# keyConverter The key converter to/from Connects struct
keyConverter: "io.confluent.connect.avro.AvroConverter"

# valueConverter The key converter to/from Connects struct
valueConverter: "io.confluent.connect.avro.AvroConverter"

# connectorClass
connectorClass: "com.datamountaineer.streamreactor.connect.ftp.source.FtpSourceConnector"

# applicationId name of the connector
applicationId: "__REQUIRED__"

# keystyle what the output key is set to: `string` => filename; `struct` => structure with filename and offset type: STRING importance: HIGH
keystyle: "__REQUIRED__"

# maxPollRecords Max number of records returned per poll type: INT importance: LOW
maxPollRecords: 10000

# sourcerecordconverter TODO type: CLASS importance: HIGH
sourcerecordconverter: com.datamountaineer.streamreactor.connect.ftp.source.NopSourceRecordConverter

# monitorTail comma separated lists of path:destinationtopic; tail of file is tracked type: LIST importance: HIGH
monitorTail: 

# maxBackoff on failure, exponentially backoff to at most this ISO8601 duration type: STRING importance: HIGH
maxBackoff: PT30M

# fileconverter TODO type: CLASS importance: HIGH
fileconverter: com.datamountaineer.streamreactor.connect.ftp.source.SimpleFileConverter

# refresh how often the ftp server is polled; ISO8601 duration type: STRING importance: HIGH
refresh: "__REQUIRED__"

# fileMaxage ignore files older than this; ISO8601 duration type: STRING importance: HIGH
fileMaxage: "__REQUIRED__"

# monitorUpdate comma separated lists of path:destinationtopic; whole file is tracked type: LIST importance: HIGH
monitorUpdate: 

# address ftp address[:port] type: STRING importance: HIGH
address: "__REQUIRED__"

# user ftp user name to login type: STRING importance: HIGH
user: "__REQUIRED__"

# protocol FTPS or FTP protocol type: STRING importance: LOW
protocol: ftp

# password ftp password key to login type in the secret
password: "__REQUIRED__"

#bufferSize The internal buffer size
bufferSize: 102400

# socketBufferSize The SO_SNDBUF buffer size
socketBufferSize: 204800