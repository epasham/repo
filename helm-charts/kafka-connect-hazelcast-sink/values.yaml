# Basic info
replicaCount: 1
# secretsRef The secret holding any passwords
secretsRef: "__REQUIRED__"
image:
  repository: streamreactor/hazelcast
  tag: 1.2.2
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

podManagementPolicy: OrderedReady

# kafka ssl
# The key and truststores file data are the base64 encoded contents of the files. YOU MUST PROVIDE THE DATA BASE64 encoded
# and added to the kafka secret and mounted into /mnt/connector-secrets
kafka:
  # replicationFactor for connect topics
  replicationFactor: 3
  securityProtocol:
  ssl:
    enabled: false
    trustStoreFileData:
    trustStorePassword:
    keyStoreFileData:
    keyStorePassword:
  sasl:
    enabled: false
    # keyTabData is the contents kerberos keytab file is using kerberos
    keyTabData: |-
             
    # jaasFileData is the contents of the kafka jaas file
    jaasFileData: |-
          
    #GSSAPI, SCRAM or PLAIN
    mechanism: GSSAPI
    # kerberos krb5 contents
    krb5Conf: |-

  bootstrapServers: 
    - name: kafka
      port: 9092
      sslPort: 9093
      saslSslPort: 9094
      saslPlainTextPort: 9095       

schemaRegistries:
  enabled: true
  hosts:
    - host: schema-registry
      protocol: http
      port: 8081
      jmxPort: 9102    

        
# secretsProvider is either env (k8), vault (hashicorp) or azure (keyvault)
secretsProvider: env

#javaHeap option
javaHeap: "256M"

# clusterName The connect cluster name. This is the consumer group id for the backing topics
clusterName: "__REQUIRED__"

# restPort The rest port of Connect
restPort: 8083

# logLevel The log4j level
logLevel: INFO

# keyConverter The key converter to/from Connects struct
keyConverter: "io.confluent.connect.avro.AvroConverter"

# valueConverter The key converter to/from Connects struct
valueConverter: "io.confluent.connect.avro.AvroConverter"

# connectorClass
connectorClass: "com.datamountaineer.streamreactor.connect.hazelcast.sink.HazelCastSinkConnector"

# applicationId name of the connector
applicationId: "__REQUIRED__"

# kcql connect.hazelcast.kcql type: STRING importance: HIGH
kcql: "__REQUIRED__"

topics: "__REQUIRED__"

# maxRetries The maximum number of times to try the write again. type: INT importance: MEDIUM
maxRetries: 20

# retryInterval The time in milliseconds between retries. type: INT importance: MEDIUM
retryInterval: 60000

# enabled Enables the output for how many records have been processed type: BOOLEAN importance: MEDIUM
progressEnabled: true

# errorPolicy Specifies the action to be taken if an error occurs while inserting the data.
# There are two available options:
# NOOP - the error is swallowed
# THROW - the error is allowed to propagate.
# RETRY - The exception causes the Connect framework to retry the message. The number of retries is based on
# The error will be logged automatically type: STRING importance: HIGH
errorPolicy: THROW

# lingerSeconds Enables/disables SO_LINGER with the specified linger time in seconds.
# The default value is 3. type: INT importance: LOW
lingerSeconds: 3

# clusterMembers 
# Address List is the initial list of cluster addresses to which the client will connect.
# The client uses this list to find an alive node. Although it may be enough to give only one
# address of a node in the cluster (since all nodes communicate with each other),
# it is recommended that you give the addresses for all the nodes. type: LIST importance: HIGH
clusterMembers: "__REQUIRED__"

# groupPassword The password key for the group name stored in the secret. type: PASSWORD importance: MEDIUM
groupPassword: "__REQUIRED__"

# groupName The group name of the connector in the target Hazelcast cluster. type: STRING importance: HIGH
groupName: "__REQUIRED__"

# reuseAddress Enables/disables the SO_REUSEADDR socket option. The default value is true. type: BOOLEAN importance: LOW
reuseAddress: true

# keepAlive Enables/disables the SO_KEEPALIVE socket option. The default value is true. type: BOOLEAN importance: LOW
keepAlive: true

# bufferSize Sets the SO_SNDBUF and SO_RCVBUF options to the specified value in KB for this Socket.
# The default value is 32. type: INT importance: LOW
bufferSize: 32

# timeout 
# Connection timeout is the timeout value in milliseconds for nodes to
# accept client connection requests. type: LONG importance: LOW
timeout: 5000

# tcpNoDelay Enables/disables the TCP_NODELAY socket option. The default value is true. type: BOOLEAN importance: LOW
tcpNoDelay: true

# retries Number of times a client will retry the connection at startup. type: INT importance: LOW
retries: 2

# threadpoolSize 
# The sink inserts all the data concurrently. To fail fast in case of an error, the sink has its own thread pool.
# Set the value to zero and the threadpool will default to 4* NO_OF_CPUs. Set a value greater than 0
# and that would be the size of this threadpool. type: INT importance: MEDIUM
threadpoolSize: 0

# parallelWrite All the sink to write in parallel the records received from Kafka on each poll. type: BOOLEAN importance: MEDIUM
parallelWrite: false
